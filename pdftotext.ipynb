{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    " \n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.pdfinterp import PDFPageInterpreter\n",
    "from pdfminer.pdfinterp import PDFResourceManager\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    resource_manager = PDFResourceManager()\n",
    "    fake_file_handle = io.StringIO()\n",
    "    converter = TextConverter(resource_manager, fake_file_handle)\n",
    "    page_interpreter = PDFPageInterpreter(resource_manager, converter)\n",
    " \n",
    "    with open(pdf_path, 'rb') as fh:\n",
    "        for page in PDFPage.get_pages(fh, \n",
    "                                      caching=True,\n",
    "                                      check_extractable=True):\n",
    "            page_interpreter.process_page(page)\n",
    " \n",
    "        text = fake_file_handle.getvalue()\n",
    "    #print(text)\n",
    "    # close open handles\n",
    "    converter.close()\n",
    "    fake_file_handle.close()\n",
    " \n",
    "    if text:\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' 1. What is Data? Data is the information which is stored by a computer. This data can be of any form i.e., text documents, images, audios, videos etc. This data can be processessed from one computer to another computer or devices using internet.    2. How are Data generating? Data generating is the process of creating data from the sampled collected data. It is done once the data collection process is completed. It analysis the collected data and creates the processed data from it. 3. What is Big Data? Big data consists of a vast data with a voluminous storage. This collected from different data sources which is comparatively larger than the traditional data processing softwares. This vast data can be used in order to access for different purpose that could solve business problems.  \\x0c'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text1=extract_text_from_pdf('word.pdf')\n",
    "text1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize,word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' 1.',\n",
       " 'What is Data?',\n",
       " 'Data is the information which is stored by a computer.',\n",
       " 'This data can be of any form i.e., text documents, images, audios, videos etc.',\n",
       " 'This data can be processessed from one computer to another computer or devices using internet.',\n",
       " '2.',\n",
       " 'How are Data generating?',\n",
       " 'Data generating is the process of creating data from the sampled collected data.',\n",
       " 'It is done once the data collection process is completed.',\n",
       " 'It analysis the collected data and creates the processed data from it.',\n",
       " '3.',\n",
       " 'What is Big Data?',\n",
       " 'Big data consists of a vast data with a voluminous storage.',\n",
       " 'This collected from different data sources which is comparatively larger than the traditional data processing softwares.',\n",
       " 'This vast data can be used in order to access for different purpose that could solve business problems.']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_s= nltk.sent_tokenize(text1)\n",
    "text_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\chaithu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "punctuation=re.compile(r'[-.@#%^*<>=&$?!/\\,:;()|0-9]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_punc=[]\n",
    "for i in text_s:\n",
    "    i=punctuation.sub(\"\",i)\n",
    "    if len(i)>0:\n",
    "        text_punc.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'What is Data',\n",
       " 'Data is the information which is stored by a computer',\n",
       " 'This data can be of any form ie text documents images audios videos etc',\n",
       " 'This data can be processessed from one computer to another computer or devices using internet',\n",
       " 'How are Data generating',\n",
       " 'Data generating is the process of creating data from the sampled collected data',\n",
       " 'It is done once the data collection process is completed',\n",
       " 'It analysis the collected data and creates the processed data from it',\n",
       " 'What is Big Data',\n",
       " 'Big data consists of a vast data with a voluminous storage',\n",
       " 'This collected from different data sources which is comparatively larger than the traditional data processing softwares',\n",
       " 'This vast data can be used in order to access for different purpose that could solve business problems']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_punc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_word=[]\n",
    "for i in text_punc:\n",
    "    text_word.append(word_tokenize(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " ['What', 'is', 'Data'],\n",
       " ['Data',\n",
       "  'is',\n",
       "  'the',\n",
       "  'information',\n",
       "  'which',\n",
       "  'is',\n",
       "  'stored',\n",
       "  'by',\n",
       "  'a',\n",
       "  'computer'],\n",
       " ['This',\n",
       "  'data',\n",
       "  'can',\n",
       "  'be',\n",
       "  'of',\n",
       "  'any',\n",
       "  'form',\n",
       "  'ie',\n",
       "  'text',\n",
       "  'documents',\n",
       "  'images',\n",
       "  'audios',\n",
       "  'videos',\n",
       "  'etc'],\n",
       " ['This',\n",
       "  'data',\n",
       "  'can',\n",
       "  'be',\n",
       "  'processessed',\n",
       "  'from',\n",
       "  'one',\n",
       "  'computer',\n",
       "  'to',\n",
       "  'another',\n",
       "  'computer',\n",
       "  'or',\n",
       "  'devices',\n",
       "  'using',\n",
       "  'internet'],\n",
       " ['How', 'are', 'Data', 'generating'],\n",
       " ['Data',\n",
       "  'generating',\n",
       "  'is',\n",
       "  'the',\n",
       "  'process',\n",
       "  'of',\n",
       "  'creating',\n",
       "  'data',\n",
       "  'from',\n",
       "  'the',\n",
       "  'sampled',\n",
       "  'collected',\n",
       "  'data'],\n",
       " ['It',\n",
       "  'is',\n",
       "  'done',\n",
       "  'once',\n",
       "  'the',\n",
       "  'data',\n",
       "  'collection',\n",
       "  'process',\n",
       "  'is',\n",
       "  'completed'],\n",
       " ['It',\n",
       "  'analysis',\n",
       "  'the',\n",
       "  'collected',\n",
       "  'data',\n",
       "  'and',\n",
       "  'creates',\n",
       "  'the',\n",
       "  'processed',\n",
       "  'data',\n",
       "  'from',\n",
       "  'it'],\n",
       " ['What', 'is', 'Big', 'Data'],\n",
       " ['Big',\n",
       "  'data',\n",
       "  'consists',\n",
       "  'of',\n",
       "  'a',\n",
       "  'vast',\n",
       "  'data',\n",
       "  'with',\n",
       "  'a',\n",
       "  'voluminous',\n",
       "  'storage'],\n",
       " ['This',\n",
       "  'collected',\n",
       "  'from',\n",
       "  'different',\n",
       "  'data',\n",
       "  'sources',\n",
       "  'which',\n",
       "  'is',\n",
       "  'comparatively',\n",
       "  'larger',\n",
       "  'than',\n",
       "  'the',\n",
       "  'traditional',\n",
       "  'data',\n",
       "  'processing',\n",
       "  'softwares'],\n",
       " ['This',\n",
       "  'vast',\n",
       "  'data',\n",
       "  'can',\n",
       "  'be',\n",
       "  'used',\n",
       "  'in',\n",
       "  'order',\n",
       "  'to',\n",
       "  'access',\n",
       "  'for',\n",
       "  'different',\n",
       "  'purpose',\n",
       "  'that',\n",
       "  'could',\n",
       "  'solve',\n",
       "  'business',\n",
       "  'problems']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', 'What is Data', 'Data is the information which is stored by a computer', 'This data can be of any form ie text documents images audios videos etc', 'This data can be processessed from one computer to another computer or devices using internet', 'How are Data generating', 'Data generating is the process of creating data from the sampled collected data', 'It is done once the data collection process is completed', 'It analysis the collected data and creates the processed data from it', 'What is Big Data', 'Big data consists of a vast data with a voluminous storage', 'This collected from different data sources which is comparatively larger than the traditional data processing softwares', 'This vast data can be used in order to access for different purpose that could solve business problems']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "#example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "#word_tokens = word_tokenize(text1) \n",
    "  \n",
    "text_sw = [w for w in text_punc if not w in stop_words] \n",
    "  \n",
    "text_sw= [] \n",
    "  \n",
    "for w in text_punc: \n",
    "    if w not in text_sw: \n",
    "        text_sw.append(w) \n",
    "  \n",
    "#print(word_tokens) \n",
    "print(text_sw) \n",
    "#len(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What:what',\n",
       " 'is:is',\n",
       " 'Data:data',\n",
       " 'Data:data',\n",
       " 'is:is',\n",
       " 'the:the',\n",
       " 'information:inform',\n",
       " 'which:which',\n",
       " 'is:is',\n",
       " 'stored:store',\n",
       " 'by:by',\n",
       " 'a:a',\n",
       " 'computer:comput',\n",
       " 'This:thi',\n",
       " 'data:data',\n",
       " 'can:can',\n",
       " 'be:be',\n",
       " 'of:of',\n",
       " 'any:ani',\n",
       " 'form:form',\n",
       " 'ie:ie',\n",
       " 'text:text',\n",
       " 'documents:document',\n",
       " 'images:imag',\n",
       " 'audios:audio',\n",
       " 'videos:video',\n",
       " 'etc:etc',\n",
       " 'This:thi',\n",
       " 'data:data',\n",
       " 'can:can',\n",
       " 'be:be',\n",
       " 'processessed:processess',\n",
       " 'from:from',\n",
       " 'one:one',\n",
       " 'computer:comput',\n",
       " 'to:to',\n",
       " 'another:anoth',\n",
       " 'computer:comput',\n",
       " 'or:or',\n",
       " 'devices:devic',\n",
       " 'using:use',\n",
       " 'internet:internet',\n",
       " 'How:how',\n",
       " 'are:are',\n",
       " 'Data:data',\n",
       " 'generating:gener',\n",
       " 'Data:data',\n",
       " 'generating:gener',\n",
       " 'is:is',\n",
       " 'the:the',\n",
       " 'process:process',\n",
       " 'of:of',\n",
       " 'creating:creat',\n",
       " 'data:data',\n",
       " 'from:from',\n",
       " 'the:the',\n",
       " 'sampled:sampl',\n",
       " 'collected:collect',\n",
       " 'data:data',\n",
       " 'It:It',\n",
       " 'is:is',\n",
       " 'done:done',\n",
       " 'once:onc',\n",
       " 'the:the',\n",
       " 'data:data',\n",
       " 'collection:collect',\n",
       " 'process:process',\n",
       " 'is:is',\n",
       " 'completed:complet',\n",
       " 'It:It',\n",
       " 'analysis:analysi',\n",
       " 'the:the',\n",
       " 'collected:collect',\n",
       " 'data:data',\n",
       " 'and:and',\n",
       " 'creates:creat',\n",
       " 'the:the',\n",
       " 'processed:process',\n",
       " 'data:data',\n",
       " 'from:from',\n",
       " 'it:it',\n",
       " 'What:what',\n",
       " 'is:is',\n",
       " 'Big:big',\n",
       " 'Data:data',\n",
       " 'Big:big',\n",
       " 'data:data',\n",
       " 'consists:consist',\n",
       " 'of:of',\n",
       " 'a:a',\n",
       " 'vast:vast',\n",
       " 'data:data',\n",
       " 'with:with',\n",
       " 'a:a',\n",
       " 'voluminous:volumin',\n",
       " 'storage:storag',\n",
       " 'This:thi',\n",
       " 'collected:collect',\n",
       " 'from:from',\n",
       " 'different:differ',\n",
       " 'data:data',\n",
       " 'sources:sourc',\n",
       " 'which:which',\n",
       " 'is:is',\n",
       " 'comparatively:compar',\n",
       " 'larger:larger',\n",
       " 'than:than',\n",
       " 'the:the',\n",
       " 'traditional:tradit',\n",
       " 'data:data',\n",
       " 'processing:process',\n",
       " 'softwares:softwar',\n",
       " 'This:thi',\n",
       " 'vast:vast',\n",
       " 'data:data',\n",
       " 'can:can',\n",
       " 'be:be',\n",
       " 'used:use',\n",
       " 'in:in',\n",
       " 'order:order',\n",
       " 'to:to',\n",
       " 'access:access',\n",
       " 'for:for',\n",
       " 'different:differ',\n",
       " 'purpose:purpos',\n",
       " 'that:that',\n",
       " 'could:could',\n",
       " 'solve:solv',\n",
       " 'business:busi',\n",
       " 'problems:problem']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "pst= PorterStemmer()\n",
    "sub_stem=[]\n",
    "for words in text_word:\n",
    "    for i in words:\n",
    "        sub_stem.append(i+ \":\" +pst.stem(i))\n",
    "sub_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['What:What',\n",
       " 'is:is',\n",
       " 'Data:Data',\n",
       " 'Data:Data',\n",
       " 'is:is',\n",
       " 'the:the',\n",
       " 'information:information',\n",
       " 'which:which',\n",
       " 'is:is',\n",
       " 'stored:stored',\n",
       " 'by:by',\n",
       " 'a:a',\n",
       " 'computer:computer',\n",
       " 'This:This',\n",
       " 'data:data',\n",
       " 'can:can',\n",
       " 'be:be',\n",
       " 'of:of',\n",
       " 'any:any',\n",
       " 'form:form',\n",
       " 'ie:ie',\n",
       " 'text:text',\n",
       " 'documents:document',\n",
       " 'images:image',\n",
       " 'audios:audio',\n",
       " 'videos:video',\n",
       " 'etc:etc',\n",
       " 'This:This',\n",
       " 'data:data',\n",
       " 'can:can',\n",
       " 'be:be',\n",
       " 'processessed:processessed',\n",
       " 'from:from',\n",
       " 'one:one',\n",
       " 'computer:computer',\n",
       " 'to:to',\n",
       " 'another:another',\n",
       " 'computer:computer',\n",
       " 'or:or',\n",
       " 'devices:device',\n",
       " 'using:using',\n",
       " 'internet:internet',\n",
       " 'How:How',\n",
       " 'are:are',\n",
       " 'Data:Data',\n",
       " 'generating:generating',\n",
       " 'Data:Data',\n",
       " 'generating:generating',\n",
       " 'is:is',\n",
       " 'the:the',\n",
       " 'process:process',\n",
       " 'of:of',\n",
       " 'creating:creating',\n",
       " 'data:data',\n",
       " 'from:from',\n",
       " 'the:the',\n",
       " 'sampled:sampled',\n",
       " 'collected:collected',\n",
       " 'data:data',\n",
       " 'It:It',\n",
       " 'is:is',\n",
       " 'done:done',\n",
       " 'once:once',\n",
       " 'the:the',\n",
       " 'data:data',\n",
       " 'collection:collection',\n",
       " 'process:process',\n",
       " 'is:is',\n",
       " 'completed:completed',\n",
       " 'It:It',\n",
       " 'analysis:analysis',\n",
       " 'the:the',\n",
       " 'collected:collected',\n",
       " 'data:data',\n",
       " 'and:and',\n",
       " 'creates:creates',\n",
       " 'the:the',\n",
       " 'processed:processed',\n",
       " 'data:data',\n",
       " 'from:from',\n",
       " 'it:it',\n",
       " 'What:What',\n",
       " 'is:is',\n",
       " 'Big:Big',\n",
       " 'Data:Data',\n",
       " 'Big:Big',\n",
       " 'data:data',\n",
       " 'consists:consists',\n",
       " 'of:of',\n",
       " 'a:a',\n",
       " 'vast:vast',\n",
       " 'data:data',\n",
       " 'with:with',\n",
       " 'a:a',\n",
       " 'voluminous:voluminous',\n",
       " 'storage:storage',\n",
       " 'This:This',\n",
       " 'collected:collected',\n",
       " 'from:from',\n",
       " 'different:different',\n",
       " 'data:data',\n",
       " 'sources:source',\n",
       " 'which:which',\n",
       " 'is:is',\n",
       " 'comparatively:comparatively',\n",
       " 'larger:larger',\n",
       " 'than:than',\n",
       " 'the:the',\n",
       " 'traditional:traditional',\n",
       " 'data:data',\n",
       " 'processing:processing',\n",
       " 'softwares:software',\n",
       " 'This:This',\n",
       " 'vast:vast',\n",
       " 'data:data',\n",
       " 'can:can',\n",
       " 'be:be',\n",
       " 'used:used',\n",
       " 'in:in',\n",
       " 'order:order',\n",
       " 'to:to',\n",
       " 'access:access',\n",
       " 'for:for',\n",
       " 'different:different',\n",
       " 'purpose:purpose',\n",
       " 'that:that',\n",
       " 'could:could',\n",
       " 'solve:solve',\n",
       " 'business:business',\n",
       " 'problems:problem']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lem=WordNetLemmatizer()\n",
    "lem_stem=[]\n",
    "for words in text_word:\n",
    "    for i in words:\n",
    "        lem_stem.append(i+ \":\" +lem.lemmatize(i))\n",
    "lem_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' ',\n",
       " 'what is data',\n",
       " 'data is the information which is stored by a computer',\n",
       " 'this data can be of any form ie text documents images audios videos etc',\n",
       " 'this data can be processessed from one computer to another computer or devices using internet',\n",
       " 'how are data generating',\n",
       " 'data generating is the process of creating data from the sampled collected data',\n",
       " 'it is done once the data collection process is completed',\n",
       " 'it analysis the collected data and creates the processed data from it',\n",
       " 'what is big data',\n",
       " 'big data consists of a vast data with a voluminous storage',\n",
       " 'this collected from different data sources which is comparatively larger than the traditional data processing softwares',\n",
       " 'this vast data can be used in order to access for different purpose that could solve business problems']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_low=[x.lower() for x in text_punc]\n",
    "text_low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\chaithu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "sw = stopwords.words('english')\n",
    "for i in range(len(text_s)):\n",
    "    words = nltk.word_tokenize(text_s[i])\n",
    "    words = [word for word in words if word not in stopwords.words('english')]\n",
    "    text_s[i] = ' '.join(words) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What:what', 'is:is', 'Data:data', 'Data:data', 'is:is', 'the:the', 'information:inform', 'which:which', 'is:is', 'stored:store', 'by:by', 'a:a', 'computer:comput', 'This:thi', 'data:data', 'can:can', 'be:be', 'of:of', 'any:ani', 'form:form', 'ie:ie', 'text:text', 'documents:document', 'images:imag', 'audios:audio', 'videos:video', 'etc:etc', 'This:thi', 'data:data', 'can:can', 'be:be', 'processessed:processess', 'from:from', 'one:one', 'computer:comput', 'to:to', 'another:anoth', 'computer:comput', 'or:or', 'devices:devic', 'using:use', 'internet:internet', 'How:how', 'are:are', 'Data:data', 'generating:gener', 'Data:data', 'generating:gener', 'is:is', 'the:the', 'process:process', 'of:of', 'creating:creat', 'data:data', 'from:from', 'the:the', 'sampled:sampl', 'collected:collect', 'data:data', 'It:It', 'is:is', 'done:done', 'once:onc', 'the:the', 'data:data', 'collection:collect', 'process:process', 'is:is', 'completed:complet', 'It:It', 'analysis:analysi', 'the:the', 'collected:collect', 'data:data', 'and:and', 'creates:creat', 'the:the', 'processed:process', 'data:data', 'from:from', 'it:it', 'What:what', 'is:is', 'Big:big', 'Data:data', 'Big:big', 'data:data', 'consists:consist', 'of:of', 'a:a', 'vast:vast', 'data:data', 'with:with', 'a:a', 'voluminous:volumin', 'storage:storag', 'This:thi', 'collected:collect', 'from:from', 'different:differ', 'data:data', 'sources:sourc', 'which:which', 'is:is', 'comparatively:compar', 'larger:larger', 'than:than', 'the:the', 'traditional:tradit', 'data:data', 'processing:process', 'softwares:softwar', 'This:thi', 'vast:vast', 'data:data', 'can:can', 'be:be', 'used:use', 'in:in', 'order:order', 'to:to', 'access:access', 'for:for', 'different:differ', 'purpose:purpos', 'that:that', 'could:could', 'solve:solv', 'business:busi', 'problems:problem']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize \n",
    "  \n",
    "#example_sent = \"This is a sample sentence, showing off the stop words filtration.\"\n",
    "  \n",
    "stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "#word_tokens = word_tokenize(text1) \n",
    "  \n",
    "filtered_sentence = [w for w in sub_stem if not w in stop_words] \n",
    "  \n",
    "filtered_sentence = [] \n",
    "  \n",
    "for w in sub_stem: \n",
    "    if w not in stop_words: \n",
    "        filtered_sentence.append(w) \n",
    "  \n",
    "#print(word_tokens) \n",
    "print(filtered_sentence) \n",
    "len(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\chaithu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tag import DefaultTagger\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagging = DefaultTagger('NN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_pos=[]\n",
    "for words in text_word:\n",
    "    words=nltk.pos_tag(words)\n",
    "    text_pos.append(words)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[],\n",
       " [('What', 'WP'), ('is', 'VBZ'), ('Data', 'NNP')],\n",
       " [('Data', 'NNP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('information', 'NN'),\n",
       "  ('which', 'WDT'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('stored', 'VBN'),\n",
       "  ('by', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('computer', 'NN')],\n",
       " [('This', 'DT'),\n",
       "  ('data', 'NN'),\n",
       "  ('can', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('of', 'IN'),\n",
       "  ('any', 'DT'),\n",
       "  ('form', 'NN'),\n",
       "  ('ie', 'NN'),\n",
       "  ('text', 'NN'),\n",
       "  ('documents', 'NNS'),\n",
       "  ('images', 'VBZ'),\n",
       "  ('audios', 'NNS'),\n",
       "  ('videos', 'NNS'),\n",
       "  ('etc', 'VBP')],\n",
       " [('This', 'DT'),\n",
       "  ('data', 'NN'),\n",
       "  ('can', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('processessed', 'VBN'),\n",
       "  ('from', 'IN'),\n",
       "  ('one', 'CD'),\n",
       "  ('computer', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('another', 'DT'),\n",
       "  ('computer', 'NN'),\n",
       "  ('or', 'CC'),\n",
       "  ('devices', 'NNS'),\n",
       "  ('using', 'VBG'),\n",
       "  ('internet', 'NN')],\n",
       " [('How', 'WRB'), ('are', 'VBP'), ('Data', 'NNP'), ('generating', 'NN')],\n",
       " [('Data', 'NNP'),\n",
       "  ('generating', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('process', 'NN'),\n",
       "  ('of', 'IN'),\n",
       "  ('creating', 'VBG'),\n",
       "  ('data', 'NNS'),\n",
       "  ('from', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('sampled', 'VBN'),\n",
       "  ('collected', 'VBN'),\n",
       "  ('data', 'NNS')],\n",
       " [('It', 'PRP'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('done', 'VBN'),\n",
       "  ('once', 'RB'),\n",
       "  ('the', 'DT'),\n",
       "  ('data', 'NNS'),\n",
       "  ('collection', 'NN'),\n",
       "  ('process', 'NN'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('completed', 'VBN')],\n",
       " [('It', 'PRP'),\n",
       "  ('analysis', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('collected', 'VBN'),\n",
       "  ('data', 'NNS'),\n",
       "  ('and', 'CC'),\n",
       "  ('creates', 'VBZ'),\n",
       "  ('the', 'DT'),\n",
       "  ('processed', 'VBN'),\n",
       "  ('data', 'NN'),\n",
       "  ('from', 'IN'),\n",
       "  ('it', 'PRP')],\n",
       " [('What', 'WP'), ('is', 'VBZ'), ('Big', 'JJ'), ('Data', 'NNS')],\n",
       " [('Big', 'NNP'),\n",
       "  ('data', 'NN'),\n",
       "  ('consists', 'VBZ'),\n",
       "  ('of', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('vast', 'JJ'),\n",
       "  ('data', 'NN'),\n",
       "  ('with', 'IN'),\n",
       "  ('a', 'DT'),\n",
       "  ('voluminous', 'JJ'),\n",
       "  ('storage', 'NN')],\n",
       " [('This', 'DT'),\n",
       "  ('collected', 'VBN'),\n",
       "  ('from', 'IN'),\n",
       "  ('different', 'JJ'),\n",
       "  ('data', 'NNS'),\n",
       "  ('sources', 'NNS'),\n",
       "  ('which', 'WDT'),\n",
       "  ('is', 'VBZ'),\n",
       "  ('comparatively', 'RB'),\n",
       "  ('larger', 'JJR'),\n",
       "  ('than', 'IN'),\n",
       "  ('the', 'DT'),\n",
       "  ('traditional', 'JJ'),\n",
       "  ('data', 'NN'),\n",
       "  ('processing', 'NN'),\n",
       "  ('softwares', 'NNS')],\n",
       " [('This', 'DT'),\n",
       "  ('vast', 'JJ'),\n",
       "  ('data', 'NNS'),\n",
       "  ('can', 'MD'),\n",
       "  ('be', 'VB'),\n",
       "  ('used', 'VBN'),\n",
       "  ('in', 'IN'),\n",
       "  ('order', 'NN'),\n",
       "  ('to', 'TO'),\n",
       "  ('access', 'NN'),\n",
       "  ('for', 'IN'),\n",
       "  ('different', 'JJ'),\n",
       "  ('purpose', 'NN'),\n",
       "  ('that', 'WDT'),\n",
       "  ('could', 'MD'),\n",
       "  ('solve', 'VB'),\n",
       "  ('business', 'NN'),\n",
       "  ('problems', 'NNS')]]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tw1= nltk.pos_tag(text_word)\n",
    "\n",
    "\n",
    "word_tags = []\n",
    "for tw in tw1:\n",
    "    word_tags.append(tw[0]+\"_\"+tw[1])\n",
    "\n",
    "tagged_paragraph = ' '.join(tw1)\n",
    "\n",
    "tagged_paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
